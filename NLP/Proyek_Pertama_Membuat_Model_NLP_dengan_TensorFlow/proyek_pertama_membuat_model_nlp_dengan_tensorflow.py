# -*- coding: utf-8 -*-
"""Proyek Pertama : Membuat Model NLP dengan TensorFlow.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vqfSSaex_qjtpkZ4ed9UGbDKi_JHGQ-g

#Proyek Pertama : Membuat Model NLP dengan TensorFlow


---

Daniel Shandy Adryan

1494037162101-932

danielshandy34@gmail.com

# Preparation

Importing the package, library, or API
"""

import pandas as pd
import sklearn
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
import tensorflow as tf
import matplotlib.pyplot as plt

"""defining classes and variables to shorten the syntaxes"""

#set stopwords to english
stop = set(stopwords.words('english'))

#classes used for training and testing
class txtrecog():
  tts = sklearn.model_selection.train_test_split
  tknzr = tf.keras.preprocessing.text.Tokenizer
  pseq = tf.keras.utils.pad_sequences

#classes used for creating models layer for training
class layer():
  lstm = tf.keras.layers.LSTM
  dns = tf.keras.layers.Dense
  dropout = tf.keras.layers.Dropout
  embed = tf.keras.layers.Embedding
  bn = tf.keras.layers.BatchNormalization

#classes used for callbacks
class scall(tf.keras.callbacks.Callback):
  def on_epoch_end(self, epochs, logs={}):
    if (logs.get('val_accuracy') > 0.76):
      print ('Pelatihan Dihentikan Karena Akurasi Sudah Mencapai Nilai yang Diinginkan')
      self.model.stop_training = True

"""# Data Wrangling

Reading the csv-files, using stopwords, and seperate the punctuation
"""

#reading csv files
df = pd.read_csv('/content/wine-reviews.csv',usecols = ['country', 'description', 'points', 'price', 'variety', 'winery'])

df.dropna(subset=["description", "points"], inplace = True)
df.drop_duplicates(subset=["description", "points"], inplace = True)
df.isnull().sum()
df['description'] = df['description'].str.lower()
df.head()

"""Plotting 'Points' Columns and converting it into int32 type"""

plt.hist(df.points, bins=20)
plt.title("Points histogram")
plt.ylabel("N")
plt.xlabel("Points")
plt.show()

df["label"] = (df.points >= 90).astype(int)
df = df[["description", "label"]]

"""defining stopwords"""

def del_stop_words (x):
  return ' '.join([ w for w in str(x).split() if w not in (stop) ])
df["description"] = df["description"].apply(lambda x: del_stop_words (x))
df.head()

"""seperating the punctuation"""

tknz = nltk.RegexpTokenizer(r"\w+|\S+")
df["description"] = df["description"].apply(lambda x: ".".join([ w for w in (tknz.tokenize(x)) ]))
df.tail()

"""inserting the values of selected columns into a few variables"""

plot = df['description'].values
label = df[['label']].values

"""# Text Tokenization

seperating the datasets into validation data and train data
"""

Plot_train, Plot_test, label_train, label_test = txtrecog.tts(plot, label, test_size=0.2)

"""text tokenization process"""

tokenizer = txtrecog.tknzr(num_words=7000, oov_token='-')
tokenizer.fit_on_texts(Plot_train) 

seq_train = tokenizer.texts_to_sequences(Plot_train)
seq_tst = tokenizer.texts_to_sequences(Plot_test)

pad_train = txtrecog.pseq(
    seq_train,
    maxlen=30,
    padding='post',
    truncating='post') 
pad_tst = txtrecog.pseq(
    seq_tst,
    maxlen=30,
    padding='post',
    truncating='post')

"""# Training and Modelling

Modelling and compiling the NN
"""

mdl = tf.keras.Sequential()
mdl.add(layer.embed(input_dim=7000, output_dim=32, mask_zero=True))
mdl.add(layer.bn())
mdl.add(layer.lstm(32))
mdl.add(layer.dns(2, activation='relu'))
mdl.add(layer.bn())
mdl.add(layer.dropout(0.4))
mdl.add(layer.dns(4, activation='relu'))
mdl.add(layer.bn())
mdl.add(layer.dropout(0.4))
mdl.add(layer.dns(8, activation='relu'))
mdl.add(layer.bn())
mdl.add(layer.dropout(0.4))
mdl.add(layer.dns(1, activation='sigmoid'))

mdl.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])

"""Training the model"""

hstr = mdl.fit(pad_train, label_train, epochs= 30,
                    validation_data=(pad_tst, label_test),
                    callbacks = [scall()], verbose=2)

"""# Plotting

Loss Plotting
"""

plt.plot(hstr.history['loss'], label = 'Latih')
plt.plot(hstr.history['val_loss'], label = 'Test')
plt.legend()

"""Accuracy Plotting"""

plt.plot(hstr.history['accuracy'], label = 'Latih')
plt.plot(hstr.history['val_accuracy'], label = 'Test')
plt.legend()